# ICP-5

#### Complete the following:
```
Name: Anil Kumar Kochera
Email: akkw32@umsystem.edu
```
---
```
Partner Name: Charunya Poola
Partner Email: cpxyd@umsystem.edu
Partner ICP-Link: https://github.com/UMKC-APL-PythonDeepLearing/icp_5-Charunya25

```
### SUBMIT PYTHON NOTEBOOK FILE (ipynb files)

```
Video Link: (if not submitting in class) 
```
<br/>
 
Write brief explanation here:

<!Doctype html>

<html>

<body>


<h1> Python/Deep Learning Course - CSEE-5590 </h1>


<hr size="1" noshade>


<h2> Program - 1 Titanic Dataset- </h2>
<br>

<p> Step: 1 - We import pandas and numpy for data loading and data preprocessing, matplotlib for visualization, train_test_split from scikit learn for training and testing data, svm, KNN Classifiers for prediction. </p>
<p> Step: 2 - loading the datasets train and test and make the categorical variable values to 0 for male and 1 for female in train csv </p>
<p> Step: 3 - Finding the correlation between two columns </p>
<p> Step: 4 - Visualizing Survivded,Gender and Survived, Pclass </p>
<p> Step: 5 - Heatmap to show correlation between each feature using seaborn sns.heatmap method and FAcetgrid usingsns.FacetGrid method </p>
<p> Step: 6 - Drop the unnecessary columns </p>
<p> Step: 7 - Combine both test and traing data to make a list dataset </p>
<p> Step: 8 - Replace the null values with mean of the Age and other columns </p>
<p> Step: 9 - Apply Linear Support Vector Classifier (SVC) method to perform classification </p>
<p> Step: 10 - Use svm model to find the accuracy </p>
<p> Step: 11 - svc.predict to predict the classification and similarly for KNN and Bernoulli Naive Bayes </p>
<p> Step: 12 - Create a confusion matrix for Bernoulli, Gausssian result, Multinomial result prediction results </p>



<hr size="1" noshade>

<h2> Program 2 - Optical Recognition of Handwritten Digits Data Set</h2>
<br>

<p> Step: 1 - Import all the necessary libraries such as pandas, numpy, matplotlib.pyplot, train_test_split, KNeighborsClassifier, svm, datasets</p>
<p> Step: 2 - Then, Load load_digits() for digits data from scikit learn library which is already preprocessed.</p>
<p> Step: 3 - Use train_test_split method to split the data into training and testing</p>
<p> Step: 4 - Use SVC classifier to perform classification, fit and predict</p>
<p> Step: 5 - Use SVC classifier to perform classification, fit and predict</p>
<p> Step: 6 - Appliying the accuracy_score using Y_predicted (SVC result) and Y_test data (Actual data)</p>
<p> Step: 7 - Use for loop to show all the images in the dataset</p>
<p> Step: 8 - Now using knn model with neighbors as 1 to 9, and then performing accuracy calculation operation on the predicted result.</p>
<p> Step: 9 - Using classification_report to generate the classification_report()</p>
<p> Step: 10 - Using Matplotlib method subplots to show list of images. Fig is the figure that is returned by subplots.
We used zip method to zip.  zip() method takes iterable and returns a single iterator object having mapped values from all the containers It is used to map the similar index of multiple containers so that they can be used just using a single entity.</p>
<p> Step: 11 - Naive Bayes classification using BernouliNB. Finding bnb score using score method on XTest and YTest.</p>
<p> Step: 12 - Naive Bayes classification using Guassian NB. Finding gnb score using score method on XTest and YTest.</p>
<p> Step: 13 - Naive Bayes classification using MultinomialNB. Finding mnb score using score method on XTest and YTest.</p>

<br>

</body>

</html>
